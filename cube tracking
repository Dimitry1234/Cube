import cv2
import mediapipe as mp
import numpy as np
import time

# Initialize webcam, Mediapipe Hands model, and drawing utilities
webcam = cv2.VideoCapture(0)

# Setup Mediapipe Hands model for hand tracking
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)
mp_drawing = mp.solutions.drawing_utils

# Define color ranges for each Rubik's cube face (broadened ranges)
colors = {
    "red": ((160, 40, 40), (180, 255, 255)),
    "green": ((35, 40, 40), (85, 255, 255)),
    "blue": ((90, 40, 40), (150, 255, 255)),
    "yellow": ((15, 70, 70), (35, 255, 255)),
    "orange": ((5, 70, 70), (25, 255, 255)),
    "white": ((0, 0, 160), (180, 50, 255)),
}

# Center positions on the Rubik's Cube
center_positions = {
    "red": None,
    "green": None,
    "blue": None,
    "yellow": None,
    "orange": None,
    "white": None
}

# Check if a center color has been saved
saved_centers = {color: False for color in center_positions}

def detect_cube_with_hand(image, results):
    """Detect cube region near the hand using Mediapipe hand landmarks."""
    if results.multi_hand_landmarks and len(results.multi_hand_landmarks) == 2:
        # Get bounding boxes for both hands
        hand_landmarks = results.multi_hand_landmarks

        x_min_1 = int(min(lm.x for lm in hand_landmarks[0].landmark) * image.shape[1])
        y_min_1 = int(min(lm.y for lm in hand_landmarks[0].landmark) * image.shape[0])
        x_max_1 = int(max(lm.x for lm in hand_landmarks[0].landmark) * image.shape[1])
        y_max_1 = int(max(lm.y for lm in hand_landmarks[0].landmark) * image.shape[0])

        x_min_2 = int(min(lm.x for lm in hand_landmarks[1].landmark) * image.shape[1])
        y_min_2 = int(min(lm.y for lm in hand_landmarks[1].landmark) * image.shape[0])
        x_max_2 = int(max(lm.x for lm in hand_landmarks[1].landmark) * image.shape[1])
        y_max_2 = int(max(lm.y for lm in hand_landmarks[1].landmark) * image.shape[0])

        # Calculate bounding box for cube between hands
        x_min = min(x_min_1, x_min_2)
        y_min = min(y_min_1, y_min_2)
        x_max = max(x_max_1, x_max_2)
        y_max = max(y_max_1, y_max_2)

        # Expand the bounding box slightly to include the cube
        margin = 30
        x_min = max(0, x_min - margin)
        y_min = max(0, y_min - margin)
        x_max = min(image.shape[1], x_max + margin)
        y_max = min(image.shape[0], y_max + margin)

        return True, (x_min, y_min, x_max - x_min, y_max - y_min)
    return False, None

while webcam.isOpened():
    success, img = webcam.read()
    if not success:
        print("Error: Could not capture frame.")
        break

    # Convert image to RGB for Mediapipe processing
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    results = hands.process(img_rgb)

    # Draw hand landmarks for debugging
    if results.multi_hand_landmarks:
        for hand_landmarks in results.multi_hand_landmarks:
            mp_drawing.draw_landmarks(img, hand_landmarks, mp_hands.HAND_CONNECTIONS)

    # Detect cube region based on hand landmarks
    is_cube_detected, cube_bounding_box = detect_cube_with_hand(img, results)

    if is_cube_detected:
        # Extract the Rubik's cube region from the image
        x_min, y_min, width, height = cube_bounding_box
        cube_region = img[y_min:y_min+height, x_min:x_min+width]

        # Draw bounding box for debugging
        cv2.rectangle(img, (x_min, y_min), (x_min + width, y_min + height), (255, 0, 0), 2)

        # Identify dominant color in each sub-region (assuming faces are roughly equal size)
        face_colors = []
        face_width = int(width / 3)
        face_height = int(height / 3)
        for i in range(3):
            row_colors = []
            for j in range(3):
                x1, y1 = i * face_width, j * face_height
                x2, y2 = x1 + face_width, y1 + face_height
                face_region = cube_region[y1:y2, x1:x2]

                # Convert to HSV color space for better color detection
                hsv_img = cv2.cvtColor(face_region, cv2.COLOR_BGR2HSV)

                # Loop through defined colors and check if it's dominant
                dominant_color = None
                for color_name, color_range in colors.items():
                    lower, upper = color_range
                    mask = cv2.inRange(hsv_img, lower, upper)
                    white_pixels = np.sum(mask == 255)
                    if white_pixels > mask.size * 0.2:  # Update condition for detection
                        dominant_color = color_name
                        break

                # Fallback: Use average color if no dominant color is found
                if not dominant_color:
                    avg_hue = np.mean(hsv_img[:, :, 0])
                    if 160 <= avg_hue <= 180 or 0 <= avg_hue <= 10:
                        dominant_color = "red"
                    elif 35 <= avg_hue <= 85:
                        dominant_color = "green"
                    elif 90 <= avg_hue <= 150:
                        dominant_color = "blue"
                    elif 15 <= avg_hue <= 35:
                        dominant_color = "yellow"
                    elif 5 <= avg_hue <= 25:
                        dominant_color = "orange"
                    else:
                        dominant_color = "white"

                # Append detected color for the region
                row_colors.append(dominant_color)
            face_colors.append(row_colors)

        # Print scanned result in terminal
        print("Scanned Cube Face:")
        for row in face_colors:
            print(" ".join(row))

        # Slow down scanning
        time.sleep(0.5)

    # Show webcam feed
    cv2.imshow("Webcam Feed", img)

    # Exit the loop if 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release resources
webcam.release()
cv2.destroyAllWindows()
